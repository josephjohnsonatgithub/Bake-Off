{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e36dc49-5561-4162-9dfa-1e7341909237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c9de9c-04b3-4a3d-9547-ec32163ffba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PullData as pdta\n",
    "import Methods as mt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98d09869-4064-42d2-ac11-4dd89dc54fc7",
   "metadata": {},
   "source": [
    "It has its strengths and weaknesses just due to the tensor completion implementation. \n",
    "\n",
    "There are a lot of ways we could further enhance the engine, including \n",
    "\n",
    "automated disaggregation, \n",
    "algorithm bake-off, \n",
    "measure recommendation, \n",
    "and collinearity tests, \n",
    "\n",
    "to name a few - which is why we have the job req out!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fde8e5e-30c1-4a5e-82cf-6afcc042de3b",
   "metadata": {},
   "source": [
    "download data\n",
    "\n",
    "-- option to transform\n",
    "\n",
    "different methods\n",
    "\n",
    "different validation\n",
    "\n",
    "test\n",
    "\n",
    "Validation\n",
    "    prequential v cross-validation\n",
    "    transform v no transform\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd15da0-dca5-4aea-b073-db92a07a4a2f",
   "metadata": {},
   "source": [
    "### Upload time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8054e771-7573-44bc-b085-b1e205de2aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "fatality_dict = pdta.GetTimeSeries()\n",
    "fatality_arr = pdta.FilterDict(fatality_dict, 0.5, 'sb_ged_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b74e1-a464-49b6-a1cc-e89264218673",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664fa2b-7c71-4a31-95b1-728102c29532",
   "metadata": {},
   "source": [
    "X_train = np.arange(36)\n",
    "y_train = np.arange(6,36)\n",
    "X_test = np.arange(36-6,39)\n",
    "\n",
    "reg = mt.EmbedDimRegressor(6)\n",
    "\n",
    "reg.fit(X_train,y_train)\n",
    "reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42256345-e131-4a83-a542-1330b5e33a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 359)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fatality_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59510974-a081-4afd-84c9-0176d832d740",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fad382-3ecb-41d3-932e-465c9bf4ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncated indexes - will be clipped from all arrays to allow for up to 36 months lag time \n",
    "num_trunc = 72+167\n",
    "\n",
    "# training samples\n",
    "num_train = 215-167\n",
    "\n",
    "# validation samples\n",
    "num_val = 36\n",
    "\n",
    "# last 36 indexes\n",
    "num_test = 36\n",
    "\n",
    "lag = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f75de0-bdff-418e-820b-afc4f6c1dc3f",
   "metadata": {},
   "source": [
    "### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c33341a3-9b7c-4508-b5d1-6ad7211faf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49851.215277777774"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_dim_mse_naive = np.zeros((fatality_arr.shape[0])) # num countries,num dimensions\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    pred_arr = np.zeros(num_test)\n",
    "    \n",
    "    for lag in range(1,num_test+1):\n",
    "    \n",
    "        # represents a country\n",
    "        emb_reg = mt.EmbedDimRegressor(num_trunc, lag, 1, num_test)\n",
    "        actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "        x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "        pred = y_train[-1]\n",
    "\n",
    "        pred_arr[lag-1] = pred\n",
    "\n",
    "    country_dim_mse_naive[arr_idx] = mean_squared_error(actual_arr,pred_arr)  \n",
    "    \n",
    "country_dim_mse_naive.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be364a-feac-4bc4-953f-9b874004d0de",
   "metadata": {},
   "source": [
    "### No Validation (just train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9433cc4-f52d-485e-8bfc-84bb4678cd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 554122.2185608796\n",
      "1 277274.21451744105\n",
      "2 184854.1140756683\n",
      "3 138751.83598516908\n",
      "4 111009.25111729337\n",
      "5 92577.32516800649\n",
      "6 79382.61896172188\n",
      "7 78409.8498781642\n",
      "8 70265.43552323912\n",
      "9 63249.699194153836\n",
      "10 57554.79993775957\n",
      "11 52759.22411913552\n",
      "12 48706.84538509712\n",
      "13 58519.421665333786\n",
      "14 57458.36770769852\n",
      "15 53909.45145605852\n",
      "16 50826.697566633244\n",
      "17 48295.750126349005\n",
      "18 45753.86912253203\n",
      "19 58919.774653276574\n",
      "20 57841.83571634071\n",
      "21 55212.9640423954\n",
      "22 53089.7180076219\n",
      "23 50975.221082417724\n"
     ]
    }
   ],
   "source": [
    "country_dim_mse_test_no_val = np.zeros((fatality_arr.shape[0],36)) # num countries,num dimensions\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    for embed_dim in range(1,37):\n",
    "    \n",
    "        # represents a country\n",
    "        pred_arr = np.zeros(num_test)\n",
    "        actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "        \n",
    "        emb_reg = mt.EmbedDimRegressor(num_trunc, lag, embed_dim, num_test)\n",
    "        x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "\n",
    "        # make one-step-ahead prediction\n",
    "        for step in range(1,num_test+1):\n",
    "            \n",
    "            emb_reg.reg.fit(x_train,y_train) \n",
    "            pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "\n",
    "            pred_arr[lag-1] = pred #(pred+pred_arr.sum())/lag\n",
    "            \n",
    "            x_train,x_test,y_train,y_test = emb_reg.CreatePrequentialData(x_train, y_train, )\n",
    "\n",
    "        \n",
    "        country_dim_mse_test_no_val[arr_idx,embed_dim-1] = mean_squared_error(actual_arr,pred_arr) \n",
    "        \n",
    "    print(arr_idx,country_dim_mse_test_no_val.sum()/((arr_idx+1)*36))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff1ebc-dc1b-44f9-b56a-e375e06245c5",
   "metadata": {},
   "source": [
    "### Use Validaton Set to Choose best OVERALL embedding dimension for each country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b33acf-5d7b-4d58-9e4f-16a5aebb200e",
   "metadata": {},
   "source": [
    "country_dim_mse_val = np.zeros((fatality_arr.shape[0],36)) # num countries,num dimensions\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    print(arr_idx)\n",
    "    \n",
    "    lag = 1\n",
    "    \n",
    "    for embed_dim in range(1,37):\n",
    "        \n",
    "        # represents a country\n",
    "        pred_arr = np.zeros(num_val)\n",
    "        actual_arr = fatality_arr[arr_idx,-num_test-num_val:-num_test]\n",
    "\n",
    "        # make one-step-ahead prediction\n",
    "        for val_idx in range(1,37):\n",
    "\n",
    "            emb_reg = mt.EmbedDimRegressor(num_trunc+val_idx-1, lag, embed_dim, 1)\n",
    "            x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx,:-val_idx-num_test+1])\n",
    "            emb_reg.reg.fit(x_train,y_train) \n",
    "            pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "            pred_arr[num_val-1] = pred #(pred+pred_arr.sum())/lag\n",
    "\n",
    "            country_dim_mse_val[arr_idx,embed_dim-1] = abs(pred - y_test) #mean_squared_error(actual_arr,pred_arr)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c7a77-2a37-453c-8fa4-c811b43612d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dim_mse_val = np.zeros((fatality_arr.shape[0],36,36)) # num countries,num dimensions\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    print(arr_idx)\n",
    "    \n",
    "    for embed_dim in range(1,37):\n",
    "        \n",
    "        # represents a country\n",
    "        pred_arr = np.zeros(num_val)\n",
    "        actual_arr = fatality_arr[arr_idx,-num_test-num_val:-num_test]\n",
    "\n",
    "        # make one-step-ahead prediction\n",
    "        for lag in range(1,37):\n",
    "\n",
    "            emb_reg = mt.EmbedDimRegressor(num_trunc, lag, embed_dim, num_val)\n",
    "            x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx,:-num_test])\n",
    "            emb_reg.reg.fit(x_train,y_train) \n",
    "            pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "            pred_arr[lag-1] = pred #(pred+pred_arr.sum())/lag\n",
    "\n",
    "            country_dim_mse_val[arr_idx,lag-1,embed_dim-1] = abs(pred - y_test) #mean_squared_error(actual_arr,pred_arr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a25c4b-a9cd-466e-a8ef-ef0b8a47aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dim_mse_test_wval = np.zeros(fatality_arr.shape[0]) # num countries,num dimensions\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    # represents a country\n",
    "    pred_arr = np.zeros(num_test)\n",
    "    actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "\n",
    "    # make one-step-ahead prediction\n",
    "    for lag in range(1,37):\n",
    "        embed_dim = country_dim_mse_val[arr_idx,lag-1].argmin()+1\n",
    "        emb_reg = mt.EmbedDimRegressor(num_trunc, lag, embed_dim, num_test)\n",
    "        x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "        emb_reg.reg.fit(x_train,y_train) \n",
    "        pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "        pred_arr[lag-1] = pred #(pred+pred_arr.sum())/lag\n",
    "        \n",
    "    #plt.plot(actual_arr)\n",
    "    #plt.plot(pred_arr)\n",
    "    #plt.show()\n",
    "        \n",
    "    country_dim_mse_test_wval[arr_idx] = mean_squared_error(actual_arr,pred_arr)  \n",
    "    \n",
    "    print(arr_idx,country_dim_mse_test_wval.sum()/((arr_idx+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36dc0c3-ee83-4b29-a7f6-6af28a36bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(country_dim_mse_test_no_val.mean(1))\n",
    "plt.plot(country_dim_mse_test_wval)\n",
    "plt.plot(country_dim_mse_naive)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2cf864-788c-4a15-a1f6-7d27c2e1de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dim_mse_test_wval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5025772c-7058-45cb-8ab7-f9454f188a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dim_mse_test_no_val.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
