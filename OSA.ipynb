{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e36dc49-5561-4162-9dfa-1e7341909237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c9de9c-04b3-4a3d-9547-ec32163ffba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PullData as pdta\n",
    "import Methods as mt\n",
    "import EnsembleUtil as eu"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98d09869-4064-42d2-ac11-4dd89dc54fc7",
   "metadata": {},
   "source": [
    "It has its strengths and weaknesses just due to the tensor completion implementation. \n",
    "\n",
    "There are a lot of ways we could further enhance the engine, including \n",
    "\n",
    "automated disaggregation, \n",
    "algorithm bake-off,         <=====\n",
    "measure recommendation,     <===== (measures for selecting ensembles)\n",
    "and collinearity tests, \n",
    "\n",
    "to name a few - which is why we have the job req out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d979d-fdc7-4819-a27f-bf504416fd4b",
   "metadata": {},
   "source": [
    "### Data Prep, Variable Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8054e771-7573-44bc-b085-b1e205de2aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "fatality_dict = pdta.GetTimeSeries()\n",
    "fatality_arr = pdta.FilterDict(fatality_dict, 0.5, 'sb_ged_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78fad382-3ecb-41d3-932e-465c9bf4ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncated indexes - will be clipped from all arrays to allow for up to 36 months lag time \n",
    "num_trunc = 72+167\n",
    "\n",
    "# training samples\n",
    "num_train = 215-167\n",
    "\n",
    "# validation samples\n",
    "num_val = 36\n",
    "\n",
    "# last 36 indexes\n",
    "num_test = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1f6bc-d408-40e3-a743-5821a0dcde78",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10edb244-436d-4eb8-8f74-84113c5758b2",
   "metadata": {},
   "source": [
    "### Naive: Select last y training label as prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33341a3-9b7c-4508-b5d1-6ad7211faf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dim_mse_naive = np.zeros((fatality_arr.shape[0])) # num countries\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    pred_arr = np.zeros(num_test)\n",
    "    \n",
    "    for lag in range(1,num_test+1):\n",
    "    \n",
    "        # represents a country\n",
    "        emb_reg = mt.EmbedDimRegressor(num_trunc, lag, 1, num_test)\n",
    "        actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "        x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "        pred = y_train[-1]\n",
    "\n",
    "        pred_arr[lag-1] = pred\n",
    "\n",
    "    country_dim_mse_naive[arr_idx] = mean_squared_error(actual_arr,pred_arr)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be364a-feac-4bc4-953f-9b874004d0de",
   "metadata": {},
   "source": [
    "### No Validation (just train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9433cc4-f52d-485e-8bfc-84bb4678cd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "country_dim_mse_test_no_val = np.zeros((fatality_arr.shape[0],36)) # num countries,num dimensions\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    if arr_idx%5==0:\n",
    "        print(arr_idx)\n",
    "    \n",
    "    for embed_dim in range(1,37):\n",
    "    \n",
    "        # represents a country\n",
    "        pred_arr = np.zeros(num_test)\n",
    "        actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "\n",
    "        # make one-step-ahead prediction\n",
    "        for lag in range(1,37):\n",
    "\n",
    "            emb_reg = mt.EmbedDimRegressor(num_trunc, lag, embed_dim, num_test)\n",
    "            x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "            emb_reg.reg.fit(x_train,y_train) \n",
    "            pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "\n",
    "            pred_arr[lag-1] = pred\n",
    "\n",
    "        \n",
    "        country_dim_mse_test_no_val[arr_idx,embed_dim-1] = mean_squared_error(actual_arr,pred_arr) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0261a98-377b-469c-b767-5d7850e0e0a1",
   "metadata": {},
   "source": [
    "### Use Validaton Set to Choose best embedding dimension for each lag for each country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aadf56e-7d57-4e56-bae6-9fef6d7b70c9",
   "metadata": {},
   "source": [
    "#### Validation Run (some objects will not be used until ensemble section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "763c7a77-2a37-453c-8fa4-c811b43612d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# used to find most accurate learners\n",
    "country_dim_mse_val = np.zeros((fatality_arr.shape[0],36,36)) # num countries,num lags,num dimensions\n",
    "# used to find predictions for diversity calculation\n",
    "country_dim_lag_test_preds = np.zeros((fatality_arr.shape[0],36,36)) # num countries,num lags (same as num_test),num dimensions\n",
    "# used to find predictions for diversity calculation\n",
    "country_dim_lag_train_preds = np.zeros((fatality_arr.shape[0],36,36,num_train+1)) # num countries,num lags (same as num_test),num dimensions\n",
    "\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    if arr_idx%5==0:\n",
    "        print(arr_idx)\n",
    "    \n",
    "    for embed_dim in range(1,37):\n",
    "        \n",
    "        # represents a country\n",
    "        actual_arr = fatality_arr[arr_idx,-num_test-num_val:-num_test]\n",
    "\n",
    "        # make one-step-ahead prediction\n",
    "        for lag in range(1,37):\n",
    "\n",
    "            emb_reg = mt.EmbedDimRegressor(num_trunc, lag, embed_dim, num_val)\n",
    "            x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx,:-num_test])\n",
    "            emb_reg.reg.fit(x_train,y_train) \n",
    "            pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "            train_preds = emb_reg.reg.predict(x_train)\n",
    "\n",
    "            country_dim_mse_val[arr_idx,lag-1,embed_dim-1] = abs(pred - y_test)\n",
    "            country_dim_lag_test_preds[arr_idx,lag-1,embed_dim-1] = pred\n",
    "            country_dim_lag_train_preds[arr_idx,lag-1,embed_dim-1] = train_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c1ccd0-3bc0-4517-9916-0e50219f1b23",
   "metadata": {},
   "source": [
    "#### Test Based on Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6a25c4b-a9cd-466e-a8ef-ef0b8a47aae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "country_dim_mse_test_wval = np.zeros(fatality_arr.shape[0]) # num countries\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    if arr_idx%5==0:\n",
    "        print(arr_idx)\n",
    "    \n",
    "    # represents a country\n",
    "    pred_arr = np.zeros(num_test)\n",
    "    actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "\n",
    "    # make one-step-ahead prediction\n",
    "    for lag in range(1,37):\n",
    "        embed_dim = country_dim_mse_val[arr_idx,lag-1].argmin()+1\n",
    "        emb_reg = mt.EmbedDimRegressor(num_trunc, lag, embed_dim, num_test)\n",
    "        x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "        emb_reg.reg.fit(x_train,y_train) \n",
    "        pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "        pred_arr[lag-1] = pred \n",
    "        \n",
    "    country_dim_mse_test_wval[arr_idx] = mean_squared_error(actual_arr,pred_arr)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1490a-f235-40f2-8249-fc54f5f370f3",
   "metadata": {},
   "source": [
    "### Performance Summary for Single Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce2cf864-788c-4a15-a1f6-7d27c2e1de18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE by Method\n",
      "\n",
      "Use Validation:\t 39788\n",
      "No Validation:\t 41545\n",
      "Naive:\t\t 49851\n"
     ]
    }
   ],
   "source": [
    "print('Average MSE by Method\\n')\n",
    "print('Use Validation:\\t',round(country_dim_mse_test_wval.mean()))\n",
    "print('No Validation:\\t',round(country_dim_mse_test_no_val.mean()))\n",
    "print('Naive:\\t\\t',round(country_dim_mse_naive.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db067392-c0f8-4155-9d95-5be6a741ce72",
   "metadata": {},
   "source": [
    "## Ensembles\n",
    "#### All methods select 3 learners for each country and each lag.\n",
    "#### We will average the ensemble predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6999c6-c870-4219-8b78-5dc1ea85ac89",
   "metadata": {},
   "source": [
    "### Most Accurate Learners -- choose 3 most accurate learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4d6619e-eabb-49fe-96b3-4981e5a994bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "country_dim_mse_test_wval_ens = np.zeros(fatality_arr.shape[0]) # num countries\n",
    "ensemble_size = 3\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    if arr_idx%5==0:\n",
    "        print(arr_idx)\n",
    "    \n",
    "    # represents a country\n",
    "    pred_arr = np.zeros(num_test)\n",
    "    actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "\n",
    "    # make one-step-ahead prediction\n",
    "    for lag in range(1,37):\n",
    "        embed_dim_l = (country_dim_mse_val[arr_idx,lag-1].argsort()[:ensemble_size]+1).tolist()\n",
    "        ensemble_preds = np.zeros(ensemble_size)\n",
    "        \n",
    "        for t_idx,t_embed_dim in enumerate(embed_dim_l):\n",
    "            emb_reg = mt.EmbedDimRegressor(num_trunc, lag, t_embed_dim, num_test)\n",
    "            x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "            emb_reg.reg.fit(x_train,y_train) \n",
    "            t_pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "            ensemble_preds[t_idx] = t_pred\n",
    "        \n",
    "        pred_arr[lag-1] = ensemble_preds.mean()\n",
    "        \n",
    "    country_dim_mse_test_wval_ens[arr_idx] = mean_squared_error(actual_arr,pred_arr)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4565857-b5a2-4635-8e8e-447870c3a124",
   "metadata": {},
   "source": [
    "### Random Ensemble -- choose three randomly (w/o replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0ecff5f-e5a5-4b22-bfe6-c0325335c292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "524133.8493966049\n",
      "262288.7360382223\n",
      "174863.75273260413\n",
      "131258.66872359868\n",
      "105014.72259681145\n",
      "5\n",
      "87579.02927638452\n",
      "75097.35762044377\n",
      "74477.4473629012\n",
      "66750.04402480698\n",
      "60085.17833693251\n",
      "10\n",
      "54670.40449584325\n",
      "50115.22983940702\n",
      "46266.19948515839\n",
      "54388.55637731198\n",
      "52013.42361740414\n",
      "15\n",
      "48802.23220383993\n",
      "46000.891805904525\n",
      "43743.122677737476\n",
      "41440.85352047833\n",
      "54576.90781070441\n",
      "20\n",
      "53582.49975931284\n",
      "51147.21354132493\n",
      "49176.50133424429\n",
      "47221.169072228084\n",
      "45332.32230933896\n",
      "25\n",
      "44146.522727804375\n",
      "42511.46633047829\n",
      "41171.06545073783\n",
      "39754.02783923621\n",
      "38569.125697403644\n",
      "30\n",
      "37324.9603523261\n",
      "38181.842544797786\n"
     ]
    }
   ],
   "source": [
    "country_dim_mse_test_no_val_ens = np.zeros((fatality_arr.shape[0])) # num countries\n",
    "ensemble_size = 3\n",
    "mse_l = []\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    if arr_idx%5==0:\n",
    "        print(arr_idx)\n",
    "    \n",
    "    # represents a country\n",
    "    pred_arr = np.zeros(num_test)\n",
    "    actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "\n",
    "    # make one-step-ahead prediction\n",
    "    for lag in range(1,37):\n",
    "        # randomly choose three learners\n",
    "        embed_dim_l = (np.random.choice(36,ensemble_size,replace=False)+1).tolist()\n",
    "        ensemble_preds = np.zeros(ensemble_size)\n",
    "\n",
    "        for t_idx,t_embed_dim in enumerate(embed_dim_l):\n",
    "            emb_reg = mt.EmbedDimRegressor(num_trunc, lag, t_embed_dim, num_test)\n",
    "            x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "            emb_reg.reg.fit(x_train,y_train) \n",
    "            t_pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "            ensemble_preds[t_idx] = t_pred\n",
    "\n",
    "        pred_arr[lag-1] = ensemble_preds.mean()\n",
    "        \n",
    "    country_dim_mse_test_no_val_ens[arr_idx] = mean_squared_error(actual_arr,pred_arr) \n",
    "    mse_l.append(mean_squared_error(actual_arr,pred_arr))\n",
    "    print(np.array(mse_l).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e907cd3f-1abf-460a-96d1-556164a9102d",
   "metadata": {},
   "source": [
    "### Accuracy-Diversity Measure for Selecting Ensemble Members"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f06bfa-0b98-4b04-befe-dc5cdc1015a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Acc @ Val, Div @ Train: Choose the most mutually diverse on training set predictions among the top K learners (in terms of validation accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef2d3072-8b47-4bfc-a1b2-8fffa004b913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "399190.01885833335\n",
      "199752.8909823289\n",
      "133173.32038115317\n",
      "99989.04841016699\n",
      "79999.01989969915\n",
      "5\n",
      "66733.86062798744\n",
      "57225.986609759486\n",
      "58569.743825764286\n",
      "52447.20239556942\n",
      "47209.50122142139\n",
      "10\n",
      "42976.94456456352\n",
      "39396.25330647168\n",
      "36371.5051135024\n",
      "43497.475406144644\n",
      "41966.57701350656\n",
      "15\n",
      "39376.22660422174\n",
      "37123.62385377006\n",
      "35315.402233816916\n",
      "33456.69696318131\n",
      "43051.28389528459\n",
      "20\n",
      "42694.46584339273\n",
      "40754.04157018636\n",
      "39247.31708224538\n",
      "37695.26752685579\n",
      "36187.456825781555\n",
      "25\n",
      "35329.515618334226\n",
      "34021.015039877406\n",
      "33012.78865839725\n",
      "31876.997575376303\n",
      "30969.11316842189\n",
      "30\n",
      "29970.109517827634\n",
      "30661.81063144876\n"
     ]
    }
   ],
   "source": [
    "country_dim_mse_test_wval_ens_train = np.zeros(fatality_arr.shape[0]) # num countries\n",
    "ensemble_size = 3\n",
    "K = 8\n",
    "mse_l = []\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    if arr_idx%5==0:\n",
    "        print(arr_idx)\n",
    "    \n",
    "    # represents a country\n",
    "    pred_arr = np.zeros(num_test)\n",
    "    actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "\n",
    "    # make one-step-ahead prediction\n",
    "    for lag in range(1,37):\n",
    "        embed_dim_l = eu.AccuracyDiversityEnsemble(country_dim_mse_val[arr_idx,lag-1],country_dim_lag_train_preds[arr_idx,lag-1], K, ensemble_size)\n",
    "        ensemble_preds = np.zeros(ensemble_size)\n",
    "        \n",
    "        for t_idx,t_embed_dim in enumerate(embed_dim_l):\n",
    "            emb_reg = mt.EmbedDimRegressor(num_trunc, lag, t_embed_dim, num_test)\n",
    "            x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "            emb_reg.reg.fit(x_train,y_train) \n",
    "            t_pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "            ensemble_preds[t_idx] = t_pred\n",
    "        \n",
    "        pred_arr[lag-1] = ensemble_preds.mean()\n",
    "        \n",
    "    country_dim_mse_test_wval_ens_train[arr_idx] = mean_squared_error(actual_arr,pred_arr) \n",
    "    mse_l.append(mean_squared_error(actual_arr,pred_arr))\n",
    "    print(np.array(mse_l).mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaea2ff6-7c6f-4cdb-8119-467d095175cf",
   "metadata": {},
   "source": [
    "### Acc-Div @ Validation: Choose the most mutually diverse on validation set predictions among the top K learners (in terms of validation accuracy)Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2d03694-71ad-4b5a-a022-de345a298393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "389200.5686580247\n",
      "194769.86239138307\n",
      "129851.28010675254\n",
      "97498.4725763916\n",
      "78006.56136064793\n",
      "5\n",
      "65093.868568456004\n",
      "55820.525585514326\n",
      "57495.873692561945\n",
      "51529.24736163136\n",
      "46386.26901684997\n",
      "10\n",
      "42221.60355788681\n",
      "38703.85717992492\n",
      "35732.5154303261\n",
      "42795.52610296154\n",
      "42338.97365266436\n",
      "15\n",
      "39722.09980626539\n",
      "37449.75258702057\n",
      "35679.119904105406\n",
      "33801.27156515783\n",
      "43625.0770979339\n",
      "20\n",
      "43176.08769989883\n",
      "41213.897658135225\n",
      "39695.452483244924\n",
      "38128.156781215934\n",
      "36603.0305099673\n",
      "25\n",
      "35723.0982305722\n",
      "34400.02051832878\n",
      "33362.53851022174\n",
      "32214.72338176918\n",
      "31309.997142006505\n",
      "30\n",
      "30299.997234199844\n",
      "31059.026394039665\n"
     ]
    }
   ],
   "source": [
    "import EnsembleUtil as eu\n",
    "import importlib\n",
    "importlib.reload(eu)\n",
    "\n",
    "country_dim_mse_test_wval_ens_test = np.zeros(fatality_arr.shape[0]) # num countries\n",
    "ensemble_size = 3\n",
    "K = 8\n",
    "mse_l = []\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    if arr_idx%5==0:\n",
    "        print(arr_idx)\n",
    "    \n",
    "    # represents a country\n",
    "    pred_arr = np.zeros(num_test)\n",
    "    actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "\n",
    "    # make one-step-ahead prediction\n",
    "    for lag in range(1,37):\n",
    "        embed_dim_l = eu.AccuracyDiversityEnsemble(country_dim_mse_val[arr_idx,lag-1],country_dim_lag_test_preds[arr_idx,lag-1], K, ensemble_size)\n",
    "        ensemble_preds = np.zeros(ensemble_size)\n",
    "        \n",
    "        for t_idx,t_embed_dim in enumerate(embed_dim_l):\n",
    "            emb_reg = mt.EmbedDimRegressor(num_trunc, lag, t_embed_dim, num_test)\n",
    "            x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "            emb_reg.reg.fit(x_train,y_train) \n",
    "            t_pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "            ensemble_preds[t_idx] = t_pred\n",
    "        \n",
    "        pred_arr[lag-1] = ensemble_preds.mean()\n",
    "        \n",
    "    country_dim_mse_test_wval_ens_test[arr_idx] = mean_squared_error(actual_arr,pred_arr) \n",
    "    mse_l.append(mean_squared_error(actual_arr,pred_arr))\n",
    "    print(np.array(mse_l).mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519de14-44d4-4695-9b5c-e517041f87c5",
   "metadata": {},
   "source": [
    "### Single Learner Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25484452-2810-41a0-bd46-64d65d02c018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE by Method\n",
      "\n",
      "Use Validation:\t\t\t 39788\n",
      "No Validation:\t\t\t 41545\n",
      "Naive:\t\t\t\t 49851\n"
     ]
    }
   ],
   "source": [
    "print('Average MSE by Method\\n')\n",
    "print('Use Validation:\\t\\t\\t',round(country_dim_mse_test_wval.mean()))\n",
    "print('No Validation:\\t\\t\\t',round(country_dim_mse_test_no_val.mean()))\n",
    "print('Naive:\\t\\t\\t\\t',round(country_dim_mse_naive.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f301bbd-ef5d-4db9-9184-9cfd3784f8bc",
   "metadata": {},
   "source": [
    "### Ensemble Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df732baf-4277-4c48-b07a-6186648d129f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE by Ensemble Method\n",
      "\n",
      "Acc @ Val, Div @ Train:\t\t 30662\n",
      "Acc-Div @ Validation:\t\t 31059\n",
      "Most Accurate @ Validation:\t 32100\n",
      "Random Choice:\t\t\t 38182\n"
     ]
    }
   ],
   "source": [
    "print('Average MSE by Ensemble Method\\n')\n",
    "print('Acc @ Val, Div @ Train:\\t\\t',round(country_dim_mse_test_wval_ens_train.mean()))\n",
    "print('Acc-Div @ Validation:\\t\\t',round(country_dim_mse_test_wval_ens_test.mean()))\n",
    "print('Most Accurate @ Validation:\\t',round(country_dim_mse_test_wval_ens.mean()))\n",
    "print('Random Choice:\\t\\t\\t',round(country_dim_mse_test_no_val_ens.mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
