{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e36dc49-5561-4162-9dfa-1e7341909237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c9de9c-04b3-4a3d-9547-ec32163ffba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PullData as pdta\n",
    "import Methods as mt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98d09869-4064-42d2-ac11-4dd89dc54fc7",
   "metadata": {},
   "source": [
    "It has its strengths and weaknesses just due to the tensor completion implementation. \n",
    "\n",
    "There are a lot of ways we could further enhance the engine, including \n",
    "\n",
    "automated disaggregation, \n",
    "algorithm bake-off,         <=====\n",
    "measure recommendation,     <===== (next commit)\n",
    "and collinearity tests, \n",
    "\n",
    "to name a few - which is why we have the job req out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd15da0-dca5-4aea-b073-db92a07a4a2f",
   "metadata": {},
   "source": [
    "### Upload time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8054e771-7573-44bc-b085-b1e205de2aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "fatality_dict = pdta.GetTimeSeries()\n",
    "fatality_arr = pdta.FilterDict(fatality_dict, 0.5, 'sb_ged_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b74e1-a464-49b6-a1cc-e89264218673",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42256345-e131-4a83-a542-1330b5e33a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 359)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fatality_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59510974-a081-4afd-84c9-0176d832d740",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fad382-3ecb-41d3-932e-465c9bf4ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncated indexes - will be clipped from all arrays to allow for up to 36 months lag time \n",
    "num_trunc = 72+167\n",
    "\n",
    "# training samples\n",
    "num_train = 215-167\n",
    "\n",
    "# validation samples\n",
    "num_val = 36\n",
    "\n",
    "# last 36 indexes\n",
    "num_test = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f75de0-bdff-418e-820b-afc4f6c1dc3f",
   "metadata": {},
   "source": [
    "### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c33341a3-9b7c-4508-b5d1-6ad7211faf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dim_mse_naive = np.zeros((fatality_arr.shape[0])) # num countries,num dimensions\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    pred_arr = np.zeros(num_test)\n",
    "    \n",
    "    for lag in range(1,num_test+1):\n",
    "    \n",
    "        # represents a country\n",
    "        emb_reg = mt.EmbedDimRegressor(num_trunc, lag, 1, num_test)\n",
    "        actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "        x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "        pred = y_train[-1]\n",
    "\n",
    "        pred_arr[lag-1] = pred\n",
    "\n",
    "    country_dim_mse_naive[arr_idx] = mean_squared_error(actual_arr,pred_arr)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be364a-feac-4bc4-953f-9b874004d0de",
   "metadata": {},
   "source": [
    "### No Validation (just train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9433cc4-f52d-485e-8bfc-84bb4678cd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "country_dim_mse_test_no_val = np.zeros((fatality_arr.shape[0],36)) # num countries,num dimensions\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    if arr_idx%5==0:\n",
    "        print(arr_idx)\n",
    "    \n",
    "    for embed_dim in range(1,37):\n",
    "    \n",
    "        # represents a country\n",
    "        pred_arr = np.zeros(num_test)\n",
    "        actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "\n",
    "        # make one-step-ahead prediction\n",
    "        for lag in range(1,37):\n",
    "\n",
    "            emb_reg = mt.EmbedDimRegressor(num_trunc, lag, embed_dim, num_test)\n",
    "            x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "            emb_reg.reg.fit(x_train,y_train) \n",
    "            pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "\n",
    "            pred_arr[lag-1] = pred\n",
    "\n",
    "        \n",
    "        country_dim_mse_test_no_val[arr_idx,embed_dim-1] = mean_squared_error(actual_arr,pred_arr) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0261a98-377b-469c-b767-5d7850e0e0a1",
   "metadata": {},
   "source": [
    "### Use Validaton Set to Choose best embedding dimension for each lag for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "763c7a77-2a37-453c-8fa4-c811b43612d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "country_dim_mse_val = np.zeros((fatality_arr.shape[0],36,36)) # num countries,num dimensions\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    if arr_idx%5==0:\n",
    "        print(arr_idx)\n",
    "    \n",
    "    for embed_dim in range(1,37):\n",
    "        \n",
    "        # represents a country\n",
    "        pred_arr = np.zeros(num_val)\n",
    "        actual_arr = fatality_arr[arr_idx,-num_test-num_val:-num_test]\n",
    "\n",
    "        # make one-step-ahead prediction\n",
    "        for lag in range(1,37):\n",
    "\n",
    "            emb_reg = mt.EmbedDimRegressor(num_trunc, lag, embed_dim, num_val)\n",
    "            x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx,:-num_test])\n",
    "            emb_reg.reg.fit(x_train,y_train) \n",
    "            pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "            pred_arr[lag-1] = pred #(pred+pred_arr.sum())/lag\n",
    "\n",
    "            country_dim_mse_val[arr_idx,lag-1,embed_dim-1] = abs(pred - y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6a25c4b-a9cd-466e-a8ef-ef0b8a47aae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "country_dim_mse_test_wval = np.zeros(fatality_arr.shape[0]) # num countries,num dimensions\n",
    "\n",
    "for arr_idx in range(fatality_arr.shape[0]):\n",
    "    \n",
    "    if arr_idx%5==0:\n",
    "        print(arr_idx)\n",
    "    \n",
    "    # represents a country\n",
    "    pred_arr = np.zeros(num_test)\n",
    "    actual_arr = fatality_arr[arr_idx,-num_test:]\n",
    "\n",
    "    # make one-step-ahead prediction\n",
    "    for lag in range(1,37):\n",
    "        embed_dim = country_dim_mse_val[arr_idx,lag-1].argmin()+1\n",
    "        emb_reg = mt.EmbedDimRegressor(num_trunc, lag, embed_dim, num_test)\n",
    "        x_train,x_test,y_train,y_test = emb_reg.CreateOffsetData(fatality_arr[arr_idx])\n",
    "        emb_reg.reg.fit(x_train,y_train) \n",
    "        pred = emb_reg.reg.predict(x_test.reshape(1,-1))\n",
    "        pred_arr[lag-1] = pred \n",
    "        \n",
    "    country_dim_mse_test_wval[arr_idx] = mean_squared_error(actual_arr,pred_arr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce2cf864-788c-4a15-a1f6-7d27c2e1de18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE by Method\n",
      "\n",
      "Use Validation:\t 38591\n",
      "No Validation:\t 41517\n",
      "Naive:\t\t 49851\n"
     ]
    }
   ],
   "source": [
    "print('Average MSE by Method\\n')\n",
    "print('Use Validation:\\t',round(country_dim_mse_test_wval.mean()))\n",
    "print('No Validation:\\t',round(country_dim_mse_test_no_val.mean()))\n",
    "print('Naive:\\t\\t',round(country_dim_mse_naive.mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
